# AI 기반 투자 리서치 자동화 SaaS 개발 워크플로우 (v2 - Gemini API PDF 처리 반영)

---

## Phase 1: 준비 및 설계 심화 (1-2주)

1.  **UI/UX 상세 설계:**
    *   기획서의 와이어프레임을 바탕으로 주요 화면(대시보드, 자료 등록, 요약 결과 뷰, 검색 결과, 스케줄 설정 등)에 대한 구체적인 UI 디자인을 Figma, Sketch 등의 도구를 사용하여 진행합니다.
    *   사용자 흐름(User Flow)을 시각화하여 가입부터 스케줄 설정 및 자동 요약 확인까지의 주요 여정을 검토하고, 어색하거나 불편한 부분은 없는지 확인합니다. 정보 입력, 결과 확인, 검색 필터링 등 핵심 상호작용의 디테일에 집중합니다.

2.  **데이터 모델링:**
    *   PostgreSQL 데이터베이스 스키마를 상세하게 설계합니다. 필요한 테이블(예: `users`, `documents`, `summaries`, `folders`, `tags`, `document_tags`, `schedules`, `schedule_sources`, `memos` 등)과 각 테이블의 컬럼(데이터 타입, 제약조건 - `NOT NULL`, `UNIQUE`, `FOREIGN KEY` 등)을 정의합니다.
    *   테이블 간의 관계(1:N, N:M)를 명확히 설정합니다. 예를 들어, `documents`와 `tags`는 N:M 관계이므로 중간 테이블(`document_tags`)이 필요합니다.
    *   `summaries` 또는 `documents` 테이블에 `pgvector`를 사용하여 벡터 임베딩을 저장할 `vector` 타입의 컬럼을 지정합니다. 벡터 차원수(Embedding 모델에 따라 다름)를 명시하고, 초기 인덱싱 전략(예: HNSW)을 구상합니다.

3.  **API 엔드포인트 설계:**
    *   FastAPI 백엔드에서 제공할 RESTful API 엔드포인트 목록을 구체적으로 정의합니다. (예: `POST /auth/register`, `POST /auth/login`, `GET /users/me`, `POST /documents`, `GET /documents/{doc_id}`, `GET /documents/{doc_id}/summary`, `GET /search`, `POST /schedules`, `GET /schedules`, `PUT /schedules/{schedule_id}` 등)
    *   각 엔드포인트의 HTTP 메소드(GET, POST, PUT, DELETE), 경로(Path), 요청 본문(Request Body - Pydantic 모델 사용), 쿼리 파라미터(Query Parameters), 응답 형식(Response Model - Pydantic 모델 사용)을 상세히 정의합니다. 이는 FastAPI의 자동 문서화(Swagger UI) 생성에 직접 활용됩니다.

4.  **기술 스택 최종 확정 및 환경 설정:**
    *   선택한 기술 스택(FastAPI, Next.js, PostgreSQL+pgvector, AWS SQS/Lambda/EventBridge 등 클라우드 서비스, Clerk/Supabase Auth 등)에 필요한 계정을 생성하고 기본적인 설정을 완료합니다.
    *   로컬 개발 환경을 구축합니다:
        *   Python 가상 환경 설정 및 FastAPI, `google-generativeai`, LangChain, DB 드라이버 등 필요한 Python 라이브러리 설치.
        *   Node.js 및 npm/yarn 설치, Next.js 프로젝트 생성 및 필요 라이브러리 설치.
        *   Docker 설치 및 PostgreSQL(+pgvector) 컨테이너 실행 설정 (로컬 DB용).
        *   클라우드 서비스 CLI 설치 및 로컬 환경에서의 인증 설정 (예: AWS CLI).
    *   Git 저장소를 생성(GitHub, GitLab 등)하고, 프런트엔드/백엔드 프로젝트 기본 구조 설정 및 초기 커밋을 수행합니다. `.gitignore` 파일을 설정하여 불필요한 파일(비밀키, 로그, 환경 설정 파일 등)이 커밋되지 않도록 합니다.

## Phase 2: 핵심 백엔드 개발 (3-4주)

5.  **인증 및 사용자 관리 구현:**
    *   선택한 인증 서비스(Clerk, Supabase Auth 등)의 가이드에 따라 FastAPI 백엔드와 연동합니다.
    *   사용자 회원가입, 이메일 인증, 로그인(토큰 발급), 로그아웃 API 엔드포인트를 구현합니다.
    *   로그인 시 발급된 JWT(JSON Web Token) 또는 세션 토큰을 검증하는 인증 미들웨어(FastAPI의 `Depends` 활용)를 구현하고, 보호가 필요한 API 엔드포인트에 적용합니다.
    *   사용자 정보 조회(`GET /users/me`) 및 간단한 프로필 업데이트 기능을 구현합니다.

6.  **데이터베이스 연동 및 기본 CRUD 구현:**
    *   SQLAlchemy(권장) 또는 다른 ORM/DB 라이브러리를 사용하여 Phase 1에서 설계한 데이터 모델을 Python 코드로 정의합니다.
    *   FastAPI 애플리케이션 설정에 데이터베이스 연결 정보를 구성하고, 애플리케이션 시작 시 DB 연결 풀이 생성되도록 설정합니다.
    *   기본적인 데이터(예: 사용자가 생성하는 폴더, 태그, 메모 등)에 대한 CRUD(Create, Read, Update, Delete) API 엔드포인트를 구현합니다. 요청 데이터 유효성 검사(Pydantic) 및 DB 작업 로직을 포함합니다. 단위 테스트 또는 API 테스트를 통해 정상 동작을 확인합니다.

7.  **백그라운드 작업 시스템 구축:**
    *   선택한 큐/워커 시스템(AWS SQS+Lambda 또는 Celery+Redis)을 설정합니다.
        *   **클라우드 서비스:** SQS 큐 생성, Lambda 함수 기본 코드 작성 및 배포, SQS 트리거 설정. IAM 권한 설정.
        *   **Celery:** Redis 서버 실행(Docker 활용 가능), Celery 설정 파일 작성(브로커 URL, 백엔드 설정 등), Celery 워커 실행 스크립트 작성.
    *   FastAPI에서 백그라운드 작업을 큐에 보내는 함수(Helper Function)를 구현합니다. 작업 내용은 직렬화 가능한 형태로 전달합니다 (예: JSON).
    *   간단한 테스트 작업(예: 로그 출력, DB 업데이트)을 FastAPI 엔드포인트에서 큐로 보내고, 백그라운드 워커(Lambda 또는 Celery 워커)가 해당 작업을 받아서 성공적으로 처리하는지 확인합니다.

8.  **수동 자료 처리 파이프라인 구현 (핵심 로직 - *Gemini API PDF 처리 반영*):**
    *   자료 입력(URL, PDF, YouTube)을 위한 `POST /documents` API 엔드포인트를 구현합니다. 요청 수신 후 입력 타입, 사용자 ID 등 기본 정보를 포함한 작업 메시지를 생성하여 백그라운드 큐에 전달하고, 사용자에게는 '처리 요청됨' 상태를 즉시 응답합니다.
    *   **백그라운드 워커 로직 상세 구현:**
        *   **작업 수신 및 초기 설정:** 큐에서 작업 메시지를 받아 필요한 정보(사용자 ID, 입력 타입, 입력 데이터 등)를 파싱합니다. DB에서 관련 사용자 정보 등을 조회합니다.
        *   **입력 소스별 처리 분기:**
            *   **PDF 처리:**
                *   (HTTP 요청으로 받은 파일을) 임시 파일로 저장하거나 메모리 내에서 직접 처리합니다.
                *   `genai.upload_file(path=pdf_file_path or file_stream)`을 호출하여 파일을 Google Cloud에 업로드하고 파일 참조(`genai.File` 객체)를 획득합니다. 파일 경로 대신 파일 객체 스트림을 직접 전달하는 것도 가능할 수 있습니다 (SDK 문서 확인).
                *   파일 업로드 중 발생할 수 있는 네트워크 오류, 용량 초과 오류, 인증 오류 등을 `try-except` 블록으로 감싸 처리하고, 실패 시 작업 상태를 '실패'로 기록합니다.
            *   **URL 처리:**
                *   `requests` 라이브러리로 URL 내용을 가져옵니다. 타임아웃, 연결 오류, 4xx/5xx 상태 코드 등을 처리합니다.
                *   `BeautifulSoup` 등을 사용하여 HTML 내용에서 본문 텍스트를 추출합니다. 메타 태그(제목, 설명 등)도 함께 추출합니다. 추출 실패 시 오류 처리합니다.
            *   **YouTube 처리:**
                *   `youtube-transcript-api` 와 같은 라이브러리를 사용하거나 관련 API를 호출하여 영상 자막(텍스트)을 추출합니다. 자막이 없거나 추출에 실패할 경우를 처리합니다.
        *   **(PDF 외) 텍스트 전처리 및 청킹:** URL, YouTube 등에서 추출된 텍스트가 Gemini API의 컨텍스트 길이 제한을 초과할 가능성이 있는 경우, LangChain의 `RecursiveCharacterTextSplitter` 등을 사용하여 의미있는 단위로 분할(청킹)합니다. PDF의 경우, `generate_content`에 파일 객체를 직접 전달하면 API가 내부적으로 처리할 가능성이 높으므로 명시적인 청킹이 필요 없을 수 있습니다 (실제 테스트를 통해 확인 필요).
        *   **Gemini API 호출 (요약, 키워드 추출):**
            *   `LLMService` 추상화 계층을 통해 API 호출 로직을 실행합니다.
            *   **PDF의 경우:** `model.generate_content(["투자 관점에서 이 문서를 요약하고 주요 키워드를 5개 추출해줘.", uploaded_pdf_file_object])` 와 같이, 적절한 프롬프트와 함께 `genai.upload_file`에서 얻은 **파일 객체 참조**를 리스트 형태로 전달합니다.
            *   **URL/YouTube의 경우:** `model.generate_content(["투자 관점에서 다음 텍스트를 요약하고 주요 키워드를 5개 추출해줘:\n\n" + extracted_text])` 와 같이, 추출/청킹된 텍스트를 프롬프트와 함께 전달합니다. (텍스트가 여러 청크일 경우, 각 청크를 처리하고 결과를 취합하는 전략 필요 - 예: MapReduce, Refine)
            *   Gemini API 호출 시 발생할 수 있는 오류(API 키 오류, Rate Limit 초과, 부적절한 콘텐츠 응답, 타임아웃 등)를 `try-except`로 처리하고, 재시도 로직을 추가하거나 작업 상태를 '실패'로 기록합니다.
        *   **결과 후처리:** API 응답에서 요약 텍스트, 추출된 키워드를 파싱합니다. 필요시 구조화된 요약 템플릿 형식에 맞게 가공합니다.
        *   **텍스트 임베딩 생성:** 요약문 또는 원문의 핵심 부분을 LangChain의 임베딩 모델 인터페이스(`OpenAIEmbeddings`, `HuggingFaceEmbeddings` 등 선택)를 통해 벡터 임베딩으로 변환합니다.
        *   **결과 DB 저장:** 처리된 결과(원본 메타데이터, 요약문, 키워드, 자동 생성된 태그, 벡터 임베딩 등)를 `documents`, `summaries`, `tags` 등 관련 테이블에 저장합니다. N:M 관계(문서-태그)를 처리합니다.
    *   처리 상태 업데이트 로직 구현: 작업 시작 시 상태를 '처리중'으로, 완료 시 '완료'로, 오류 발생 시 '실패'(오류 메시지 포함)로 DB에 기록합니다.

## Phase 3: 핵심 프런트엔드 개발 및 연동 (3-4주)

9.  **기본 레이아웃 및 인증 연동:**
    *   Next.js를 사용하여 기본적인 애플리케이션 레이아웃(헤더, 사이드바 또는 탭 네비게이션, 푸터 등)을 구성합니다. 반응형 디자인을 고려하여 Tailwind CSS 유틸리티를 활용합니다.
    *   백엔드에서 구현한 인증 API(`POST /auth/login` 등)와 연동하여 로그인/회원가입 폼 및 관련 UI 로직을 구현합니다. 로그인 성공 시 받은 토큰을 안전하게 저장(예: HttpOnly 쿠키 또는 로컬 스토리지 - 보안 고려 필요)하고, 이후 API 요청 시 헤더에 포함하여 전송합니다.
    *   로그인 상태에 따라 다른 UI(예: 로그인 버튼 vs 사용자 메뉴)를 보여주고, 보호된 페이지 접근 시 로그인 페이지로 리다이렉션하는 로직(Route Guard)을 구현합니다.

10. **핵심 기능 UI 구현 및 API 연동:**
    *   **자료 등록:** URL 입력 필드, PDF 파일 업로드 컴포넌트, YouTube 링크 입력 필드를 포함하는 자료 등록 폼 UI를 구현합니다. `POST /documents` API를 호출하고, 백엔드로부터 '처리 요청됨' 응답을 받으면 사용자에게 진행 상태(예: '요약 생성 중...')를 시각적으로 피드백합니다.
    *   **폴더 관리:** 폴더 생성, 이름 변경, 삭제 기능을 위한 UI(예: 사이드바 트리 구조) 및 관련 API 연동을 구현합니다.
    *   **요약 결과 상세 뷰:** `GET /documents/{doc_id}/summary` API를 호출하여 요약 정보를 받아옵니다. 구조화된 요약 템플릿(카드 레이아웃 등)에 맞춰 내용을 표시합니다. 추출된 키워드를 클릭 가능한 링크 형태로 보여줍니다.
    *   **메모 기능:** 요약 결과 하단 또는 측면에 간단한 텍스트 에디터(예: `textarea`)를 배치하고, 메모 저장/수정 API 연동을 구현합니다.
    *   **백그라운드 처리 상태 표시:** 문서 목록이나 상세 뷰에서 각 문서의 처리 상태('대기중', '처리중', '완료', '실패')를 아이콘이나 텍스트로 명확히 표시합니다. 주기적으로 상태를 폴링하거나, 서버 푸시(WebSocket - Post-MVP 고려)를 통해 상태 변경을 업데이트하는 방식을 고려합니다. (초기에는 수동 새로고침이나 간단한 폴링)

11. **의미 기반 검색 UI 및 기능 구현:**
    *   헤더나 메인 영역에 검색창 UI를 구현합니다. 날짜 범위 선택(Date Picker), 폴더 선택(Dropdown) 등 검색 필터 UI를 함께 배치합니다.
    *   사용자가 검색어를 입력하고 엔터를 치거나 검색 버튼을 클릭하면, 입력된 검색어와 필터 조건을 조합하여 `GET /search` API를 호출합니다.
    *   API 응답으로 받은 검색 결과(문서 목록과 관련 정보)를 리스트 형태로 화면에 렌더링합니다. 각 결과 항목에는 제목, 요약 스니펫(검색어와 관련된 부분이 하이라이트 처리되도록 백엔드 API 응답 설계 또는 프런트엔드 처리), 출처, 날짜 등을 포함합니다.
    *   API 응답에 포함된 연관 키워드/태그들을 검색 결과 상단이나 측면에 제시하여 추가 탐색을 유도합니다.

## Phase 4: 스케줄링 기능 개발 및 통합 (2-3주)

12. **스케줄링 설정 UI 및 API 구현:**
    *   **목록 뷰:** 사용자가 등록한 스케줄 모니터링 작업 목록을 보여주는 페이지를 구현합니다. 각 항목에는 설정된 이름, 대상 소스(URL/RSS), 실행 주기, 현재 상태(활성/비활성) 등을 표시하고, 수정/삭제 버튼과 함께 '새 모니터링 추가' 버튼을 제공합니다. `GET /schedules` API를 호출하여 데이터를 가져옵니다.
    *   **상세 설정 뷰 (추가/수정 모달 또는 페이지):** 사용자가 새 모니터링을 추가하거나 기존 설정을 수정하는 폼 UI를 구현합니다. 모니터링 이름 입력 필드, 대상 URL/RSS 입력 필드(여러 개 추가 가능하도록 UI 설계), 실행 주기 선택(Dropdown - 매일, 매주 특정 요일 등), 시간 설정, 적용할 요약 템플릿 선택, 저장할 폴더 선택 등의 옵션을 제공합니다. 활성/비활성 상태를 설정하는 토글 스위치를 포함합니다.
    *   폼 제출 시 `POST /schedules` (신규) 또는 `PUT /schedules/{schedule_id}` (수정) API를 호출하여 백엔드에 설정을 저장/업데이트합니다. 삭제 버튼 클릭 시 `DELETE /schedules/{schedule_id}` API를 호출합니다.

13. **스케줄러 연동 및 자동 실행 로직 구현:**
    *   **클라우드 스케줄러 설정:** AWS EventBridge Scheduler 또는 GCP Cloud Scheduler를 설정하여, 정의된 주기(예: 매 시간 정각, 매일 아침 8시)마다 특정 백엔드 엔드포인트(Webhook 형태)를 호출하거나 특정 Lambda 함수를 직접 트리거하도록 구성합니다.
    *   **스케줄러 워커 로직 상세 구현 (Webhook 엔드포인트 또는 Lambda 함수):**
        *   스케줄러로부터 트리거 신호를 받으면 실행됩니다.
        *   현재 시간에 실행되어야 하는 활성 상태의 스케줄 작업들을 DB(`schedules` 테이블)에서 조회합니다.
        *   조회된 각 스케줄 작업에 대해 다음을 수행합니다:
            *   해당 스케줄에 등록된 대상 URL/RSS 목록(`schedule_sources` 테이블 등)을 가져옵니다.
            *   각 소스 URL/RSS에 대해, 마지막으로 확인한 시점 이후 새로 발행된 콘텐츠가 있는지 확인합니다 (`feedparser`로 RSS 파싱, `requests` + `BeautifulSoup`으로 웹사이트 변경 감지 또는 특정 영역 크롤링). 신규 콘텐츠 식별 로직 및 마지막 확인 시점 기록이 필요합니다.
            *   **신규 콘텐츠 발견 시:** 해당 콘텐츠의 URL과 스케줄 설정 정보(사용자 ID, 적용할 템플릿, 저장 폴더 등)를 포함한 작업 메시지를 생성하여 **기존의 백그라운드 요약 처리 큐(Phase 2, 단계 8에서 사용한 큐)에 전달**합니다. 즉, URL 기반의 수동 자료 처리 파이프라인을 재사용합니다.
            *   오류 발생(소스 접근 불가, 파싱 실패 등) 시 로그를 기록하고 다음 스케줄로 넘어갑니다. (오류 알림은 Post-MVP)

## Phase 5: 테스트, 배포 및 개선 (지속)

14. **테스트:**
    *   **단위 테스트(Unit Testing):** 백엔드에서 중요한 비즈니스 로직 함수(예: 특정 형식 파싱, 복잡한 계산, 유틸리티 함수), 데이터 모델 검증 로직 등에 대해 `pytest` 와 같은 프레임워크를 사용하여 개별적으로 테스트 코드를 작성하고 실행합니다. Mock 객체를 활용하여 외부 의존성(DB, API 호출)을 격리하고 테스트합니다.
    *   **통합 테스트(Integration Testing):** FastAPI의 `TestClient`를 사용하여 실제 API 엔드포인트 호출 시뮬레이션을 수행합니다. 요청부터 응답까지의 전체 흐름, 데이터베이스 연동(실제 테스트 DB 사용), 백그라운드 큐에 작업 전달 여부 등을 테스트합니다. 스케줄링 트리거부터 실제 요약 결과 저장까지의 흐름도 테스트 시나리오를 구성하여 검증합니다.
    *   **E2E (End-to-End) 테스트 (수동 중심):** 실제 사용자의 입장에서 회원가입부터 시작하여 주요 기능(자료 등록 - PDF/URL/YouTube, 요약 결과 확인, 검색, 필터링, 폴더 관리, 메모, 스케줄 설정, 자동 요약 결과 확인 등)을 시나리오에 따라 직접 수행합니다.
        *   **다양한 PDF 파일 테스트:** 단순 텍스트 PDF, 복잡한 표/이미지 포함 PDF, 다단 레이아웃, 스캔된 이미지 기반 PDF(OCR 성능 확인 필요 시), 비밀번호 설정 PDF(처리 불가 확인), 대용량 PDF(처리 시간/성능 확인) 등 **Gemini API의 파일 처리 능력과 한계를 파악하기 위한 다양한 케이스**를 테스트합니다.
        *   다양한 웹사이트 URL(동적 콘텐츠 사이트 포함), YouTube 영상(자막 유무) 등 여러 종류의 입력 소스를 테스트합니다.
        *   다양한 브라우저(Chrome, Firefox, Safari 등) 및 화면 크기(데스크톱, 태블릿, 모바일)에서 UI/UX가 정상적으로 동작하는지 확인합니다(크로스 브라우징 및 반응형 테스트).

15. **배포:**
    *   프런트엔드(Next.js): Vercel, Netlify, AWS Amplify 등 정적/SSR 호스팅 서비스에 배포합니다. Git 저장소와 연동하여 CI/CD 파이프라인을 구축하면 푸시 시 자동 빌드 및 배포가 가능합니다.
    *   백엔드(FastAPI): Docker 컨테이너로 빌드하여 AWS ECS/Fargate, Google Cloud Run, Azure Container Apps 등 컨테이너 오케스트레이션 또는 서버리스 컨테이너 플랫폼에 배포합니다. 또는 EC2/VM에 직접 배포할 수도 있지만 관리 부담이 큽니다. CI/CD 파이프라인을 구축하여 배포를 자동화합니다.
    *   데이터베이스(PostgreSQL+pgvector): AWS RDS, Google Cloud SQL, Supabase 등 관리형 데이터베이스 서비스를 사용하는 것을 강력히 권장합니다. 직접 설치/운영은 전문 지식과 많은 노력이 필요합니다.
    *   백그라운드 시스템: AWS Lambda 함수 및 SQS 큐, EventBridge Scheduler 등 클라우드 네이티브 서비스는 해당 클라우드 콘솔 또는 IaC(Infrastructure as Code - 예: Terraform, AWS CDK) 도구를 통해 배포 및 관리합니다. Celery/Redis를 사용한다면 별도의 서버/컨테이너에 배포 및 관리가 필요합니다.
    *   **환경 변수 관리:** API 키(Gemini, 클라우드 서비스 등), 데이터베이스 비밀번호, JWT 시크릿 키 등 민감한 정보는 코드에 하드코딩하지 않고 환경 변수로 주입합니다. 배포 환경의 환경 변수 설정 기능을 사용하거나, AWS Secrets Manager, GCP Secret Manager 등 비밀 관리 서비스를 활용합니다.
    *   도메인 구매 및 DNS 설정을 통해 서비스 URL을 연결합니다. HTTPS 적용을 위해 SSL/TLS 인증서(Let's Encrypt 등 무료 인증서 활용 가능)를 발급받고 웹 서버 또는 로드 밸런서에 설정합니다.

16. **모니터링 및 로깅 설정:**
    *   **오류 추적:** Sentry, Bugsnag 등 오류 추적 서비스를 연동하여 프런트엔드 및 백엔드에서 발생하는 예외/오류를 실시간으로 수집하고 알림을 받도록 설정합니다. 오류 발생 시 스택 트레이스, 사용자 환경 정보 등을 함께 기록하여 디버깅에 활용합니다.
    *   **로깅:** FastAPI 백엔드 및 백그라운드 워커에서 발생하는 주요 이벤트(요청 처리 시작/종료, 중요 함수 호출, 오류 발생 등)를 로그로 기록합니다. JSON 형식으로 구조화된 로그를 출력하면 나중에 분석하기 용이합니다. CloudWatch Logs, Google Cloud Logging 등 클라우드 로깅 서비스를 활용하여 로그를 중앙에서 수집하고 검색/분석합니다.
    *   **(선택) 성능/사용량 모니터링:** 클라우드 서비스에서 제공하는 기본 메트릭(CPU 사용률, 메모리 사용량, API 호출 수, 응답 시간 등)을 모니터링합니다. Datadog, New Relic 등 APM(Application Performance Monitoring) 도구를 도입하면 더 상세한 성능 분석이 가능하지만 초기에는 필수적이지 않을 수 있습니다. Google Analytics 등을 프런트엔드에 연동하여 사용자 행동 데이터를 수집할 수도 있습니다.

17. **출시 및 피드백 반영:**
    *   내부 테스트 및 지인 대상 알파 테스트를 거쳐 안정성을 확보한 후, 소규모 사용자 그룹을 대상으로 베타 테스트를 진행하거나 초기 버전을 정식 출시합니다.
    *   사용자 피드백을 수집할 수 있는 채널(예: 서비스 내 피드백 폼, 이메일 문의, 커뮤니티 게시판 등)을 마련하고 적극적으로 소통합니다.
    *   수집된 피드백과 모니터링 데이터를 분석하여 발견된 버그를 수정하고, 사용성이 불편한 부분을 개선하며, 사용자 요구가 많은 기능(Post-MVP 로드맵의 기능들)을 우선순위에 따라 개발하여 지속적으로 서비스를 업데이트하고 개선해 나갑니다.
